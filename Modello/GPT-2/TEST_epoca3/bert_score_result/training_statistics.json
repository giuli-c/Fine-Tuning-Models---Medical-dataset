{
    "evaluation_frequency": {
        "frequency": 1,
        "period": "epoch"
    },
    "test": {
        "RISPOSTE": {
            "loss": [
                3.8950014114379883,
                3.5935356616973877,
                3.4193437099456787
            ],
            "next_token_perplexity": [
                24322.05859375,
                23563.9921875,
                23111.00390625
            ],
            "perplexity": [
                29307.892578125,
                29326.091796875,
                29326.84765625
            ],
            "sequence_accuracy": [
                0.0,
                0.0,
                0.0
            ],
            "token_accuracy": [
                0.005489925388246775,
                0.005339395720511675,
                0.00527985580265522
            ]
        },
        "combined": {
            "loss": [
                3.8950014114379883,
                3.5935356616973877,
                3.4193437099456787
            ]
        }
    },
    "training": {
        "RISPOSTE": {
            "loss": [
                4.878228187561035,
                4.222951889038086,
                3.7142019271850586
            ],
            "next_token_perplexity": [
                25849.888671875,
                25308.16796875,
                24522.68359375
            ],
            "perplexity": [
                29051.736328125,
                29327.51953125,
                29345.0625
            ],
            "sequence_accuracy": [
                0.0,
                0.0,
                0.0
            ],
            "token_accuracy": [
                0.011822405271232128,
                0.0060603260062634945,
                0.005664772819727659
            ]
        },
        "combined": {
            "loss": [
                4.878228187561035,
                4.222951889038086,
                3.7142019271850586
            ]
        }
    },
    "validation": {
        "RISPOSTE": {
            "loss": [
                3.952664375305176,
                3.649902582168579,
                3.4836525917053223
            ],
            "next_token_perplexity": [
                24552.90625,
                23784.39453125,
                23318.916015625
            ],
            "perplexity": [
                29345.0625,
                29364.041015625,
                29363.95703125
            ],
            "sequence_accuracy": [
                0.0,
                0.0,
                0.0
            ],
            "token_accuracy": [
                0.005408617202192545,
                0.005121096037328243,
                0.005209065042436123
            ]
        },
        "combined": {
            "loss": [
                3.952664375305176,
                3.649902582168579,
                3.4836525917053223
            ]
        }
    }
}